В этой папке находится проект по обработке текста.\
Определение токсичности комментариев.

## Формат

Проект сделан в Jupyter notebook: Toxic_comments(NLP).ipynb

## Описание задачи

В интернет-магазине пользователи могут дополнять описания товаров.\
Клиенты предлагают свои правки и комментируют изменения других.\
Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\
Нужно построить модель, которая будет определять позитивный комментарий, или негативный.

## Описание файла с данными

Использован файл toxic_comments.csv.\
Это комментарии с разметкой об их токсичности.\
*в репозиторий не выложен

## Описание данных

Столбец *text* - это текст комментария, а *toxic* — целевой признак.\
Если пост позитивный, то метка «1», если негативный — «0».

## Результат

Текстовые данные были переведены в векторные.\
Далее задача решалась с помощью ML.\
Лучше всего по предоставленным данным предсказывает токсичные комментарии CatBoost.\
Но он ресурсозатратен.\
LGBM дает чуть менее лучшее качество, но работает быстрее.\
Обе модели презентуются заказчику для выбора.


